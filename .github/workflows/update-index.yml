name: Update PyPI Index

on:
  workflow_dispatch: # Allows manual trigger to index existing releases
  release:
    types: [published, edited, released] # Triggers automatically on new releases

permissions:
  contents: read  # Required to list releases
  pages: write    # Required to deploy to GitHub Pages
  id-token: write # Required for OIDC authentication (Pages)

jobs:
  build-index:
    name: Generate PEP 503 Index
    runs-on: ubuntu-latest
    steps:
      - name: Setup Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.12'

      - name: Generate Index HTML
        env:
          GH_TOKEN: ${{ secrets.GITHUB_TOKEN }}
          REPO: ${{ github.repository }}
          PKG_NAME: "pydantic-core" # The exact package name
        run: |
          mkdir -p site
          
          # Inline Python script to generate PEP 503 compliant HTML
          cat <<EOF > generate_index.py
          import os
          import json
          import subprocess
          import sys

          repo = os.environ['REPO']
          pkg_name = os.environ['PKG_NAME']
          
          # PEP 503 Normalization: names should be kebab-case (hyphens) and lowercase
          # e.g., pydantic_core -> pydantic-core
          normalized_name = pkg_name.replace('_', '-').lower()

          print(f"üîç Fetching releases for {repo}...")
          
          # Fetch all releases using GitHub CLI
          # We extract the direct download URL (url) and the filename (name)
          cmd = ["gh", "release", "list", "--repo", repo, "--limit", "200", "--json", "assets"]
          result = subprocess.run(cmd, capture_output=True, text=True)
          
          if result.returncode != 0:
              print(f"‚ùå Error fetching releases: {result.stderr}")
              sys.exit(1)

          releases = json.loads(result.stdout)
          
          # Target Directory: site/pydantic-core/index.html
          target_dir = f"site/{normalized_name}"
          os.makedirs(target_dir, exist_ok=True)
          
          wheel_count = 0
          html_links = []

          for release in releases:
              for asset in release['assets']:
                  name = asset['name']
                  url = asset['url']
                  
                  if name.endswith('.whl'):
                      # Create a simple anchor link for pip
                      html_links.append(f'<a href="{url}">{name}</a>')
                      wheel_count += 1

          # Generate Package Index HTML
          html_content = f"""<!DOCTYPE html>
          <html>
          <body>
              <h1>Links for {normalized_name}</h1>
              {'<br>'.join(html_links)}
          </body>
          </html>"""
          
          with open(f"{target_dir}/index.html", "w") as f:
              f.write(html_content)
              
          # Generate Root Index (for human navigation)
          with open("site/index.html", "w") as f:
              f.write(f'<html><body><h1>My Termux Wheels</h1><a href="{normalized_name}/">{normalized_name}</a></body></html>')

          print(f"‚úÖ Generated index for {normalized_name} containing {wheel_count} wheels.")
          EOF
          
          python3 generate_index.py

      - name: Upload Pages Artifact
        uses: actions/upload-pages-artifact@v3
        with:
          path: site

  deploy:
    name: Deploy to GitHub Pages
    needs: build-index
    runs-on: ubuntu-latest
    environment:
      name: github-pages
      url: ${{ steps.deployment.outputs.page_url }}
    steps:
      - name: Deploy to GitHub Pages
        id: deployment
        uses: actions/deploy-pages@v4